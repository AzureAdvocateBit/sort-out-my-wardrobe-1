{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using Azure Notebooks to run a Deep learning Keras model to classify fashion items"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Looking to start building your own custom machine learning code using Deep Learning Libraries/Toolkits - [Keras](https://keras.io/) is a great high level API to use to do this.\n\nIn the code below we build a model from the Fashion MNIST dataset to classify clothing items into 10 categories. The data can be found here: https://github.com/zalandoresearch/fashion-mnist\n\nBecause we are using Azure Notebooks, all packages and frameworks are already installed on the free compute. So we only need to import the packages we need! \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* Import Tensorflow framework and Keras. As well as other more basic python packages"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "> You can change the backend used in Keras from Tensorflow to CNTK by simply changing the `os.environ['KERAS_BACKEND']` variable to `cntk`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nimport os\nimport time\nfrom sklearn.metrics import confusion_matrix\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\nprint(\"tensorflow Version is: \" + str(tf.__version__))\n\nimport numpy as np\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nfrom keras import backend as K\nprint(os.environ['KERAS_BACKEND'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* Import all the Keras functions we will need to use to create a Convolutional Neural Network (CNN)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\nfrom keras.datasets import fashion_mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import utils, losses, optimizers\nimport matplotlib.pyplot as plt",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* We setup some variables for example how many classes there are [0-9] as well as batch size to send the training sample of data in to the model and epochs is how many iterations/run thoroughs of the data there are\n* Each image is of size 28 x 28 pixels"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#no. of classes\nnum_classes = 10\n\n# batch size and training iterations (epochs)\nbatch_size = 128\nepochs = 10\n\n#input image dimensions\nimg_rows,img_cols = 28,28",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* In this section lets have a look at the data\n* we pull in the fashion MNIST data from the Keras library into training and testing sets\n* X stands for features and y stands for labels\n* From the shape statements in the output you can see there are 60,000! training images and 10,000 test images - so a lot more data to use in this model\n* We then show one of the images from the training set and the corresponding text label for the image\n\n> change the img_index field to any number between 0 - 60000 to see different images"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#data for train and testing\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\nprint(x_train.shape, 'train set')\nprint(x_test.shape, 'test set')\n\n# Define the text labels\nfashion_mnist_labels = [\"Top\",          # index 0\n                        \"Trouser\",      # index 1\n                        \"Jumper\",       # index 2 \n                        \"Dress\",        # index 3 \n                        \"Coat\",         # index 4\n                        \"Sandal\",       # index 5\n                        \"Shirt\",        # index 6 \n                        \"Trainer\",      # index 7 \n                        \"Bag\",          # index 8 \n                        \"Ankle boot\"]   # index 9\n\nimg_index=90\nlabel_index = y_train[img_index]\nplt.imshow(x_train[img_index])\nprint('Label Index: ' + str(label_index) + \" Fashion Labels: \" + (fashion_mnist_labels[label_index]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* In this section we normalise the data so the pixel values in the image are between 0 - 1 instead of 0 - 255 pixel values. This will help the model to converge and the math becomes easier with smaller numbers\n* We also [one-hot-encode](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science#) the labels in matrices with 0's and 1's in them only. We do this so the model does not deem any category 0-9 in a numeric ranking. For example it won't think that tshirts[0] always come before trousers[1] when actually these are IDs of the classes not something to be evaluated\n* finally as we are deadling with greyscale images we have a depth number = 1 that might be interpreted different dpending on the framework used (CNTK, Tensorflow etc)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#type convert and scale the test and training data\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\n#one-hot encoding\ny_train = utils.to_categorical(y_train, num_classes)\ny_test = utils.to_categorical(y_test,  num_classes)\n\n#formatting issues for depth of image (greyscale = 1) with different kernels (tensorflow, cntk, etc)\nif K.image_data_format()== 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0],1,img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n    x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n    input_shape = (img_rows, img_cols,1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we are able to define the Convolutional Neural Network (CNN) in layers\n\n![CNN](cnn.JPG \"CNN\")\n\n* This is a **sequential model** meaning every layer passes information forward to the next layer of the network\n* **1st Convoltuional Layer** - extracts features from data source, these are kernels/filters and feature maps. Feature maps passed to the  next layer. This layer also has a ReLu activation function - Y = max(0, x) this removes any value <0 and prevents vanishing gradients or weights <0\n* **2nd pooling layer ** - reduces dimensionality, reduce compute and helps with overfitting of the data.\n* **3rd Convolutional Layer ** -we add a Convoltuional Layer - extracts features from data source, these are kernels/filters and feature maps. Feature maps passed to the  next layer. This layer also has a ReLu activation function - Y = max(0, x) this removes any value <0 and prevents vanishing gradients or weights <0\n* **4th Pooling Layer ** - reduces dimensionality, reduce compute and helps with overfitting of the data.\n* **5th/6th Dense fully connected layer with softmax function:** put features together and classify what item of clothing is used"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "> **Run some experiments to see how when you change the model below and rerun all the code the accuarcy and model will change:**\n* add a dropout layer after the first pooling layer and also before the final dense layer: `model.add(Dropout(0.5))`\n* change the value of dropout between 0 and 1: `model.add(Dropout(X))`\n* change the 2 Conv2D layer first variable to 32 instead of 64: `model.add(Conv2D(32, kernel_size=(3,3), activation = 'relu'))`\n* Add padding to each of the Conv2D layers: `model.add(Conv2D(32, kernel_size=(3,3), padding = 'same', activation = 'relu'))`"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Define the CNN model\nmodel = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* This code compiles the CNN model and assigns loss/optimiser functions as well as metrics we wish to view\n* I start a timer so we know how long the model takes to run\n* Fit the training data to the model using 24 epoches and batches of 64 images. Pass in the test data as your validation set so we can see how the accuracy differs on the training set to the validation set as the model runs through 24 epochs\n* Finally evaluate the model using the test/validation set\n\n> Have a look at what optimisers are available in Keras and see what happens when you change this value: [https://keras.io/optimizers/](https://keras.io/optimizers/)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#compile - how to measure loss\nmodel.compile(loss=losses.categorical_crossentropy, optimizer=optimizers.Adam(), metrics=['accuracy'])\n\n#train the model and return loss and accuracy for each epoch - history dictionary\nstart = time.time()\nhist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\nend = time.time()\n\n#evaluate the model on the test data\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test Loss: ', score[0])\nprint('Test Accuracy: ', score[1])\nprint('Time to run: ', (end-start))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* This code plots the training and validation accuracy across 24 epochs\n* The training accuracy is often higher but the validation accuracy is deemed a more real world value"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "epoch_list = list(range(1, len(hist.history['acc']) + 1))\nplt.plot(epoch_list, hist.history['acc'], epoch_list, hist.history['val_acc'])\nplt.legend(('Training Accuracy', \"Validation Accuracy\"))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Margaret Maynard Reid shows us a great way to visualise a sample set output of the test results here: [https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a](https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a)\n\nRun this code to see a set of 15 images from the test set and whether the labels are assigned correctly"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predictions = model.predict(x_test)\n\n# Plot a random sample of 10 test images, their predicted labels and ground truth\nfigure = plt.figure(figsize=(20, 8))\nfor i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n    # Display each image\n    ax.imshow(np.squeeze(x_test[index]))\n    predict_index = np.argmax(predictions[index])\n    true_index = np.argmax(y_test[index])\n    # Set the title for each image\n    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n                                  fashion_mnist_labels[true_index]),\n                                  color=(\"green\" if predict_index == true_index else \"red\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Correlation Matrix\ny_pred = model.predict(x_test)\nprint(y_pred.shape)\ny_prediction = np.zeros(shape = (10000,10))\n\n#print(y_prediction)\ncount = 0\n\nfor x in y_pred:\n    index = np.argmax(x)\n    y_prediction[count, index] = 1\n    count = count + 1\n    \nprint(fashion_mnist_labels)\nconfusion_matrix(y_test.argmax(axis=1), y_prediction.argmax(axis=1))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3-azureml",
      "display_name": "Python 3.6 - AzureML",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "version": "3.6.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}